ğŸ“Œ What is Linear Regression?

Linear Regression is a supervised machine learning algorithm used to predict a continuous output based on one or more input variables.

Example:
âœ” Predict height using weight
âœ” Predict house price using area
âœ” Predict marks using study hours

The idea is simple:
ğŸ”¹ Find the "best-fitting straight line" that explains the relationship between input (x) and output (y).

Mathematically:
y^ = mx + b

Where:
x = input (weight)
y = output (height)
m = slope (how much y changes when x increases)
b = intercept (value of y when x = 0)
Å· = predicted output

ğŸ“Œ Mathematical Intuition Behind Linear Regression
The goal is to find the best values of m and b such that the line fits the data points as closely as possible.
â­ Step 1 â€” Prediction
For any weight x, predicted height:
y^ = mx + b

â­ Step 2 â€” Error (Residual)
Difference between actual and predicted:
error = y - y^

â­ Step 3 â€” Cost Function (Loss Function)
We use Mean Squared Error (MSE):
J(m,b) = 1/n âˆ‘(y-y^)^2
This measures how bad the model is.

Goal of learning:
ğŸ‘‰ Minimize the cost function â†’ find best m and b.


ğŸ“Œ How Do We Find m and b? (Gradient Descent Intuition)
Gradient descent is an optimization algorithm that moves m and b step-by-step to reduce error.

Think of it like:
ğŸ‘‰ You are walking downhill until you reach the lowest point (minimum error).

Update rules:
ğ‘š := ğ‘š âˆ’ğ›¼ âˆ‚ğ½/âˆ‚ğ‘š
b := b-ğ›¼ âˆ‚b/âˆ‚J
Where:
Î± = learning rate (step size)

This process repeats until the error stops decreasing.

ğŸ“Œ Why â€œLinearâ€ Regression?
Because the relationship between x and y is represented by a straight line.

If data is non-linear (curved), linear regression will NOT fit well.

ğŸ“Œ Assumptions of Linear Regression

1ï¸âƒ£ Linear relationship between input and output
2ï¸âƒ£ Errors are normally distributed
3ï¸âƒ£ No or minimal multicollinearity
4ï¸âƒ£ Homoscedasticity (equal variance of errors)
5ï¸âƒ£ Independent observations


ğŸ“Œ Performance Metrics for Linear Regression

Important metrics:
â­ 1. Mean Squared Error (MSE)
MSE = 1/n âˆ‘(y-y^)^2
Lower = better.

â­ 2. Root Mean Squared Error (RMSE)
RMSE = SQRT(MSE)
Also lower = better.

â­ 3. Mean Absolute Error (MAE)
MAE = 1/n âˆ‘|y-y^|
Less sensitive to outliers.

â­ 4. RÂ² Score (Coefficient of Determination)
ğ‘…**2 = 1-SS(res)/SS(tot)

Where:
SS(res) = error of model
SS(tot) = total variation

RÂ² tells you how much of the variation in Y your model explains.

Values:
1 â†’ perfect model
0 â†’ model explains nothing
Negative â†’ horrible model

ğŸ“Œ When to Use Linear Regression
âœ” Predicting continuous values
âœ” Relationship is approximately linear
âœ” Small to medium datasets
âœ” Need simple, interpretable model

ğŸ“Œ When NOT to Use Linear Regression
âŒ Data shows a curved pattern
âŒ Many outliers
âŒ Strong multicollinearity
âŒ Features interact non-linearly
âŒ You need high accuracy for complex problems

ğŸ“Œ Summary:
Linear Regression finds the best-fitting straight line between input and output variables. It works by minimizing the Mean Squared Error using optimization methods like Gradient Descent. The performance is evaluated using metrics like MSE, RMSE, MAE, and RÂ².

ğŸ¤ Interview Answer (Use This Exactly)
â€œLinear Regression is a supervised ML algorithm used to predict continuous values by modeling a linear relationship between the input and target variable. For example, if I want to predict height using weight, Linear Regression will try to draw the best-fit straight line that minimizes prediction error.
The equation is Å· = mx + b, where m is slope and b is intercept.
The model is trained by minimizing the Mean Squared Error using optimization techniques like gradient descent.
We evaluate performance using MSE, RMSE, MAE, and RÂ² score.
Linear Regression works well when the relationship is roughly linear, there are no major outliers, and variance is stable. It is simple, interpretable, and widely used as a baseline model.â€

ğŸ“Œ Linear Regression: Predict Height from Weight
This project builds a linear regression model that predicts a person's height based on their weight.

ğŸ”¥ Dataset
Weight â†’ Independent variable
Height â†’ Dependent variable

Stored in:
data/height_weight.csv

ğŸ§  Tech Stack
Python
Pandas
Scikit-learn
Matplotlib
Joblib

ğŸš€ How to Run
pip install -r requirements.txt
python train.py
python app.py

ğŸ“Š Output
Trained model saved in /model/height_predictor.pkl
Regression plot saved as /model/plot.png

